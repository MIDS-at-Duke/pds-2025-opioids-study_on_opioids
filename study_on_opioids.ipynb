{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fb3c2fc",
   "metadata": {},
   "source": [
    "## PDS Group 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f305af56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import warnings\n",
    "\n",
    "pd.set_option(\"mode.copy_on_write\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb56478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks in file: 3800\n",
      "Processing chunk 1/3800  |  0.03% completed\n",
      "Processing chunk 20/3800  |  0.53% completed\n",
      "Processing chunk 40/3800  |  1.05% completed\n",
      "Processing chunk 60/3800  |  1.58% completed\n",
      "Processing chunk 80/3800  |  2.11% completed\n",
      "Processing chunk 100/3800  |  2.63% completed\n",
      "Processing chunk 120/3800  |  3.16% completed\n",
      "Processing chunk 140/3800  |  3.68% completed\n",
      "Processing chunk 160/3800  |  4.21% completed\n",
      "Processing chunk 180/3800  |  4.74% completed\n",
      "Processing chunk 200/3800  |  5.26% completed\n",
      "Processing chunk 220/3800  |  5.79% completed\n",
      "Processing chunk 240/3800  |  6.32% completed\n",
      "Processing chunk 260/3800  |  6.84% completed\n",
      "Processing chunk 280/3800  |  7.37% completed\n",
      "Processing chunk 300/3800  |  7.89% completed\n",
      "Processing chunk 320/3800  |  8.42% completed\n",
      "Processing chunk 340/3800  |  8.95% completed\n",
      "Processing chunk 360/3800  |  9.47% completed\n",
      "Processing chunk 380/3800  |  10.00% completed\n",
      "Processing chunk 400/3800  |  10.53% completed\n",
      "Processing chunk 420/3800  |  11.05% completed\n",
      "Processing chunk 440/3800  |  11.58% completed\n",
      "Processing chunk 460/3800  |  12.11% completed\n",
      "Processing chunk 480/3800  |  12.63% completed\n",
      "Processing chunk 500/3800  |  13.16% completed\n",
      "Processing chunk 520/3800  |  13.68% completed\n",
      "Processing chunk 540/3800  |  14.21% completed\n",
      "Processing chunk 560/3800  |  14.74% completed\n",
      "Processing chunk 580/3800  |  15.26% completed\n",
      "Processing chunk 600/3800  |  15.79% completed\n",
      "Processing chunk 620/3800  |  16.32% completed\n",
      "Processing chunk 640/3800  |  16.84% completed\n",
      "Processing chunk 660/3800  |  17.37% completed\n",
      "Processing chunk 680/3800  |  17.89% completed\n",
      "Processing chunk 700/3800  |  18.42% completed\n",
      "Processing chunk 720/3800  |  18.95% completed\n",
      "Processing chunk 740/3800  |  19.47% completed\n",
      "Processing chunk 760/3800  |  20.00% completed\n",
      "Processing chunk 780/3800  |  20.53% completed\n",
      "Processing chunk 800/3800  |  21.05% completed\n",
      "Processing chunk 820/3800  |  21.58% completed\n",
      "Processing chunk 840/3800  |  22.11% completed\n",
      "Processing chunk 860/3800  |  22.63% completed\n",
      "Processing chunk 880/3800  |  23.16% completed\n",
      "Processing chunk 900/3800  |  23.68% completed\n",
      "Processing chunk 920/3800  |  24.21% completed\n",
      "Processing chunk 940/3800  |  24.74% completed\n",
      "Processing chunk 960/3800  |  25.26% completed\n",
      "Processing chunk 980/3800  |  25.79% completed\n",
      "Processing chunk 1000/3800  |  26.32% completed\n",
      "Processing chunk 1020/3800  |  26.84% completed\n",
      "Processing chunk 1040/3800  |  27.37% completed\n",
      "Processing chunk 1060/3800  |  27.89% completed\n",
      "Processing chunk 1080/3800  |  28.42% completed\n",
      "Processing chunk 1100/3800  |  28.95% completed\n",
      "Processing chunk 1120/3800  |  29.47% completed\n",
      "Processing chunk 1140/3800  |  30.00% completed\n",
      "Processing chunk 1160/3800  |  30.53% completed\n",
      "Processing chunk 1180/3800  |  31.05% completed\n",
      "Processing chunk 1200/3800  |  31.58% completed\n",
      "Processing chunk 1220/3800  |  32.11% completed\n",
      "Processing chunk 1240/3800  |  32.63% completed\n",
      "Processing chunk 1260/3800  |  33.16% completed\n",
      "Processing chunk 1280/3800  |  33.68% completed\n",
      "Processing chunk 1300/3800  |  34.21% completed\n",
      "Processing chunk 1320/3800  |  34.74% completed\n",
      "Processing chunk 1340/3800  |  35.26% completed\n",
      "Processing chunk 1360/3800  |  35.79% completed\n",
      "Processing chunk 1380/3800  |  36.32% completed\n",
      "Processing chunk 1400/3800  |  36.84% completed\n",
      "Processing chunk 1420/3800  |  37.37% completed\n",
      "Processing chunk 1440/3800  |  37.89% completed\n",
      "Processing chunk 1460/3800  |  38.42% completed\n",
      "Processing chunk 1480/3800  |  38.95% completed\n",
      "Processing chunk 1500/3800  |  39.47% completed\n",
      "Processing chunk 1520/3800  |  40.00% completed\n",
      "Processing chunk 1540/3800  |  40.53% completed\n",
      "Processing chunk 1560/3800  |  41.05% completed\n",
      "Processing chunk 1580/3800  |  41.58% completed\n",
      "Processing chunk 1600/3800  |  42.11% completed\n",
      "Processing chunk 1620/3800  |  42.63% completed\n",
      "Processing chunk 1640/3800  |  43.16% completed\n",
      "Processing chunk 1660/3800  |  43.68% completed\n",
      "Processing chunk 1680/3800  |  44.21% completed\n",
      "Processing chunk 1700/3800  |  44.74% completed\n",
      "Processing chunk 1720/3800  |  45.26% completed\n",
      "Processing chunk 1740/3800  |  45.79% completed\n",
      "Processing chunk 1760/3800  |  46.32% completed\n",
      "Processing chunk 1780/3800  |  46.84% completed\n",
      "Processing chunk 1800/3800  |  47.37% completed\n",
      "Processing chunk 1820/3800  |  47.89% completed\n",
      "Processing chunk 1840/3800  |  48.42% completed\n",
      "Processing chunk 1860/3800  |  48.95% completed\n",
      "Processing chunk 1880/3800  |  49.47% completed\n",
      "Processing chunk 1900/3800  |  50.00% completed\n",
      "Processing chunk 1920/3800  |  50.53% completed\n",
      "Processing chunk 1940/3800  |  51.05% completed\n",
      "Processing chunk 1960/3800  |  51.58% completed\n",
      "Processing chunk 1980/3800  |  52.11% completed\n",
      "Processing chunk 2000/3800  |  52.63% completed\n",
      "Processing chunk 2020/3800  |  53.16% completed\n",
      "Processing chunk 2040/3800  |  53.68% completed\n",
      "Processing chunk 2060/3800  |  54.21% completed\n",
      "Processing chunk 2080/3800  |  54.74% completed\n",
      "Processing chunk 2100/3800  |  55.26% completed\n",
      "Processing chunk 2120/3800  |  55.79% completed\n",
      "Processing chunk 2140/3800  |  56.32% completed\n",
      "Processing chunk 2160/3800  |  56.84% completed\n",
      "Processing chunk 2180/3800  |  57.37% completed\n",
      "Processing chunk 2200/3800  |  57.89% completed\n",
      "Processing chunk 2220/3800  |  58.42% completed\n",
      "Processing chunk 2240/3800  |  58.95% completed\n",
      "Processing chunk 2260/3800  |  59.47% completed\n",
      "Processing chunk 2280/3800  |  60.00% completed\n",
      "Processing chunk 2300/3800  |  60.53% completed\n",
      "Processing chunk 2320/3800  |  61.05% completed\n",
      "Processing chunk 2340/3800  |  61.58% completed\n",
      "Processing chunk 2360/3800  |  62.11% completed\n",
      "Processing chunk 2380/3800  |  62.63% completed\n",
      "Processing chunk 2400/3800  |  63.16% completed\n",
      "Processing chunk 2420/3800  |  63.68% completed\n",
      "Processing chunk 2440/3800  |  64.21% completed\n",
      "Processing chunk 2460/3800  |  64.74% completed\n",
      "Processing chunk 2480/3800  |  65.26% completed\n",
      "Processing chunk 2500/3800  |  65.79% completed\n",
      "Processing chunk 2520/3800  |  66.32% completed\n",
      "Processing chunk 2540/3800  |  66.84% completed\n",
      "Processing chunk 2560/3800  |  67.37% completed\n",
      "Processing chunk 2580/3800  |  67.89% completed\n",
      "Processing chunk 2600/3800  |  68.42% completed\n",
      "Processing chunk 2620/3800  |  68.95% completed\n",
      "Processing chunk 2640/3800  |  69.47% completed\n",
      "Processing chunk 2660/3800  |  70.00% completed\n",
      "Processing chunk 2680/3800  |  70.53% completed\n",
      "Processing chunk 2700/3800  |  71.05% completed\n",
      "Processing chunk 2720/3800  |  71.58% completed\n",
      "Processing chunk 2740/3800  |  72.11% completed\n",
      "Processing chunk 2760/3800  |  72.63% completed\n",
      "Processing chunk 2780/3800  |  73.16% completed\n",
      "Processing chunk 2800/3800  |  73.68% completed\n",
      "Processing chunk 2820/3800  |  74.21% completed\n",
      "Processing chunk 2840/3800  |  74.74% completed\n",
      "Processing chunk 2860/3800  |  75.26% completed\n",
      "Processing chunk 2880/3800  |  75.79% completed\n",
      "Processing chunk 2900/3800  |  76.32% completed\n",
      "Processing chunk 2920/3800  |  76.84% completed\n",
      "Processing chunk 2940/3800  |  77.37% completed\n",
      "Processing chunk 2960/3800  |  77.89% completed\n",
      "Processing chunk 2980/3800  |  78.42% completed\n",
      "Processing chunk 3000/3800  |  78.95% completed\n",
      "Processing chunk 3020/3800  |  79.47% completed\n",
      "Processing chunk 3040/3800  |  80.00% completed\n",
      "Processing chunk 3060/3800  |  80.53% completed\n",
      "Processing chunk 3080/3800  |  81.05% completed\n",
      "Processing chunk 3100/3800  |  81.58% completed\n",
      "Processing chunk 3120/3800  |  82.11% completed\n",
      "Processing chunk 3140/3800  |  82.63% completed\n",
      "Processing chunk 3160/3800  |  83.16% completed\n",
      "Processing chunk 3180/3800  |  83.68% completed\n",
      "Processing chunk 3200/3800  |  84.21% completed\n",
      "Processing chunk 3220/3800  |  84.74% completed\n",
      "Processing chunk 3240/3800  |  85.26% completed\n",
      "Processing chunk 3260/3800  |  85.79% completed\n",
      "Processing chunk 3280/3800  |  86.32% completed\n",
      "Processing chunk 3300/3800  |  86.84% completed\n",
      "Processing chunk 3320/3800  |  87.37% completed\n",
      "Processing chunk 3340/3800  |  87.89% completed\n",
      "Processing chunk 3360/3800  |  88.42% completed\n",
      "Processing chunk 3380/3800  |  88.95% completed\n",
      "Processing chunk 3400/3800  |  89.47% completed\n",
      "Processing chunk 3420/3800  |  90.00% completed\n",
      "Processing chunk 3440/3800  |  90.53% completed\n",
      "Processing chunk 3460/3800  |  91.05% completed\n",
      "Processing chunk 3480/3800  |  91.58% completed\n",
      "Processing chunk 3500/3800  |  92.11% completed\n",
      "Processing chunk 3520/3800  |  92.63% completed\n",
      "Processing chunk 3540/3800  |  93.16% completed\n",
      "Processing chunk 3560/3800  |  93.68% completed\n",
      "Processing chunk 3580/3800  |  94.21% completed\n",
      "Processing chunk 3600/3800  |  94.74% completed\n",
      "Processing chunk 3620/3800  |  95.26% completed\n",
      "Processing chunk 3640/3800  |  95.79% completed\n",
      "Processing chunk 3660/3800  |  96.32% completed\n",
      "Processing chunk 3680/3800  |  96.84% completed\n",
      "Processing chunk 3700/3800  |  97.37% completed\n",
      "Processing chunk 3720/3800  |  97.89% completed\n",
      "Processing chunk 3740/3800  |  98.42% completed\n",
      "Processing chunk 3760/3800  |  98.95% completed\n",
      "Processing chunk 3780/3800  |  99.47% completed\n",
      "Processing chunk 3800/3800  |  100.00% completed\n",
      "Combining chunk summaries...\n",
      "Done! Saved: arcos_by_county_year.csv\n",
      "  state     county_name  year  opioid_grams\n",
      "0    AK  ALEUTIANS EAST  2006       0.90810\n",
      "1    AK  ALEUTIANS EAST  2007       0.30270\n",
      "2    AK  ALEUTIANS EAST  2011       0.03008\n",
      "3    AK  ALEUTIANS EAST  2012       0.01504\n",
      "4    AK  ALEUTIANS EAST  2013       0.12784\n"
     ]
    }
   ],
   "source": [
    "# Ignore warnings so we can see our progress updates clearly\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.DtypeWarning)\n",
    "\n",
    "zip_path = \"/Users/far/Downloads/arcos_all.zip\"\n",
    "inner_name = \"arcos_all.tsv\"\n",
    "\n",
    "# Focus on only these columns to reduce memory usage\n",
    "needed_cols = [\n",
    "    \"BUYER_STATE\",\n",
    "    \"BUYER_COUNTY\",\n",
    "    \"TRANSACTION_DATE\",\n",
    "    \"CALC_BASE_WT_IN_GM\",\n",
    "]\n",
    "\n",
    "# Process in chunks to avoid loading the entire large file into memory at once\n",
    "# We chose 200K rather than 100K to keep the number of chunks smaller\n",
    "chunk_size = 200_000\n",
    "\n",
    "# Count chunks first so we can show accurate progress percentages during processing\n",
    "total_chunks = 0\n",
    "with zipfile.ZipFile(zip_path) as z:\n",
    "    with z.open(inner_name) as f:\n",
    "        reader = pd.read_csv(f, sep=\"\\t\", chunksize=chunk_size)\n",
    "        for _ in reader:\n",
    "            total_chunks += 1\n",
    "\n",
    "print(f\"Total chunks in file: {total_chunks}\")\n",
    "\n",
    "\n",
    "partial_results = []\n",
    "\n",
    "with zipfile.ZipFile(zip_path) as z:\n",
    "    with z.open(inner_name) as f:\n",
    "        reader = pd.read_csv(f, sep=\"\\t\", chunksize=chunk_size)\n",
    "\n",
    "        for i, chunk in enumerate(reader, start=1):\n",
    "\n",
    "            # Show periodic progress updates to monitor long-running process\n",
    "            if i % 20 == 0 or i == 1:\n",
    "                progress = i / total_chunks * 100\n",
    "                print(\n",
    "                    f\"Processing chunk {i}/{total_chunks}  |  {progress:.2f}% completed\"\n",
    "                )\n",
    "\n",
    "            # Select only needed columns to minimize memory usage\n",
    "            df = chunk[needed_cols].copy()\n",
    "\n",
    "            # Do all transformations (rename, extract year, aggregate) within each chunk\n",
    "            # to avoid creating another large dataset (~8GB) in memory\n",
    "            df = df.rename(\n",
    "                columns={\n",
    "                    \"BUYER_STATE\": \"state\",\n",
    "                    \"BUYER_COUNTY\": \"county_name\",\n",
    "                    \"TRANSACTION_DATE\": \"transaction_date\",\n",
    "                    \"CALC_BASE_WT_IN_GM\": \"opioid_grams\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "            df[\"year\"] = pd.to_datetime(df[\"transaction_date\"]).dt.year\n",
    "\n",
    "            grouped = df.groupby([\"state\", \"county_name\", \"year\"], as_index=False)[\n",
    "                \"opioid_grams\"\n",
    "            ].sum()\n",
    "\n",
    "            partial_results.append(grouped)\n",
    "\n",
    "print(\"Combining chunk summaries...\")\n",
    "\n",
    "# Combine pre-aggregated results from all chunks\n",
    "all_data = pd.concat(partial_results, ignore_index=True)\n",
    "\n",
    "# Final aggregation needed because same county-year may appear in multiple chunks\n",
    "arcos_by_county_year = all_data.groupby(\n",
    "    [\"state\", \"county_name\", \"year\"], as_index=False\n",
    ")[\"opioid_grams\"].sum()\n",
    "\n",
    "# Save to CSV for easy sharing and future use without reprocessing\n",
    "output_path = \"arcos_by_county_year.csv\"\n",
    "arcos_by_county_year.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Done! Saved:\", output_path)\n",
    "print(arcos_by_county_year.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33445fb5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
