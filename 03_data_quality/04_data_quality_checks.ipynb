{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e618f118",
   "metadata": {},
   "source": [
    "# Data Quality Validation\n",
    "\n",
    "Comprehensive validation of final merged dataset after applying 200K population threshold.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb7e225a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FINAL MERGED DATASET (≥200K POPULATION)\n",
      "============================================================\n",
      "\n",
      "Dataset shape: 1,448 observations × 18 variables\n",
      "Time period: 2006-2015\n",
      "Unique county-state combinations: 150\n",
      "States: 12\n"
     ]
    }
   ],
   "source": [
    "# Imports, settings, and load final merged dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option(\"mode.copy_on_write\", True)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "df = pd.read_csv(\"../01_data/clean/final_merged_150k.csv\")\n",
    "\n",
    "# Create county-state identifier (some county names appear in multiple states)\n",
    "df[\"county_state\"] = df[\"CTYNAME\"] + \", \" + df[\"STNAME\"]\n",
    "\n",
    "# Identify which year column to use\n",
    "year_col = \"Year\" if \"Year\" in df.columns else \"year\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FINAL MERGED DATASET (≥200K POPULATION)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nDataset shape: {df.shape[0]:,} observations × {df.shape[1]} variables\")\n",
    "print(f\"Time period: {df[year_col].min():.0f}-{df[year_col].max():.0f}\")\n",
    "print(f\"Unique county-state combinations: {df['county_state'].nunique()}\")\n",
    "print(f\"States: {df['STNAME'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44739af",
   "metadata": {},
   "source": [
    "## Missing Values Analysis\n",
    "\n",
    "Identify missing data patterns and assess impact on analysis quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a431e6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MISSING VALUES ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Variables with missing values:\n",
      "                                 Missing Count  Missing %\n",
      "merge_on_arcos                             881      60.84\n",
      "TOTAL_MME                                  881      60.84\n",
      "BUYER_COUNTY                               881      60.84\n",
      "BUYER_STATE                                881      60.84\n",
      "Deaths                                     489      33.77\n",
      "Drug/Alcohol Induced Cause Code            489      33.77\n",
      "Drug/Alcohol Induced Cause                 489      33.77\n",
      "\n",
      "------------------------------------------------------------\n",
      "KEY INSIGHTS:\n",
      "------------------------------------------------------------\n",
      "Deaths missingness: 33.77% (CDC suppression for <10 deaths)\n",
      "ARCOS missingness: 0.00% (counties with no opioid shipments)\n",
      "\n",
      "✓ All counties have population data: True\n",
      "✓ All observations have year data: True\n"
     ]
    }
   ],
   "source": [
    "# Analyze missing values and key insights\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if \"county_state\" not in df.columns:\n",
    "    df[\"county_state\"] = df[\"CTYNAME\"] + \", \" + df[\"STNAME\"]\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (df.isnull().sum() / len(df) * 100).round(2)\n",
    "missing_df = pd.DataFrame(\n",
    "    {\"Missing Count\": missing, \"Missing %\": missing_pct}\n",
    ").sort_values(\"Missing Count\", ascending=False)\n",
    "\n",
    "print(\"\\nVariables with missing values:\")\n",
    "print(missing_df[missing_df[\"Missing Count\"] > 0])\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"KEY INSIGHTS:\")\n",
    "print(\"-\" * 60)\n",
    "print(\n",
    "    f\"Deaths missingness: {missing_pct['Deaths']:.2f}% (CDC suppression for <10 deaths)\"\n",
    ")\n",
    "print(\n",
    "    f\"ARCOS missingness: {missing_pct.get('DOSAGE_UNIT', 0):.2f}% (counties with no opioid shipments)\"\n",
    ")\n",
    "print(f\"\\n✓ All counties have population data: {df['population'].notna().all()}\")\n",
    "print(f\"✓ All observations have year data: {df[year_col].notna().all()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9035f14d",
   "metadata": {},
   "source": [
    "## Temporal Coverage and Panel Balance\n",
    "\n",
    "Verify complete time series coverage (2006-2015) for all counties in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a21d717e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEMPORAL COVERAGE\n",
      "============================================================\n",
      "\n",
      "Year range: 2006 to 2015\n",
      "Total years: 10\n",
      "\n",
      "Observations per year:\n",
      "Year\n",
      "2006    135\n",
      "2007    143\n",
      "2008    143\n",
      "2009    143\n",
      "2010    146\n",
      "2011    146\n",
      "2012    147\n",
      "2013    148\n",
      "2014    147\n",
      "2015    150\n",
      "Name: count, dtype: int64\n",
      "\n",
      "------------------------------------------------------------\n",
      "PANEL BALANCE CHECK:\n",
      "------------------------------------------------------------\n",
      "Counties with complete 10-year data: 135\n",
      "Counties with incomplete data: 15\n",
      "\n",
      "Found 15 counties with incomplete time series.\n",
      "These counties crossed 200K population during 2006-2015.\n",
      "\n",
      "Counties with incomplete data (first 10):\n",
      "  - Alamance County, North Carolina: 6 years (missing 4)\n",
      "  - Beaufort County, South Carolina: 9 years (missing 1)\n",
      "  - DeSoto County, Mississippi: 9 years (missing 1)\n",
      "  - Deschutes County, Oregon: 9 years (missing 1)\n",
      "  - Dorchester County, South Carolina: 1 years (missing 9)\n",
      "  - Forsyth County, Georgia: 9 years (missing 1)\n",
      "  - Iredell County, North Carolina: 9 years (missing 1)\n",
      "  - Johnston County, North Carolina: 9 years (missing 1)\n",
      "  - Kings County, California: 8 years (missing 2)\n",
      "  - Madera County, California: 6 years (missing 4)\n",
      "\n",
      "Recommendation for difference-in-differences analysis:\n",
      "  - Use only 135 balanced counties for clean estimates\n",
      "  - OR include all counties with appropriate controls\n"
     ]
    }
   ],
   "source": [
    "# Check temporal coverage and panel balance\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TEMPORAL COVERAGE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if \"county_state\" not in df.columns:\n",
    "    df[\"county_state\"] = df[\"CTYNAME\"] + \", \" + df[\"STNAME\"]\n",
    "print(f\"\\nYear range: {df[year_col].min():.0f} to {df[year_col].max():.0f}\")\n",
    "print(f\"Total years: {df[year_col].nunique()}\")\n",
    "\n",
    "obs_per_year = df[year_col].value_counts().sort_index()\n",
    "print(\"\\nObservations per year:\")\n",
    "print(obs_per_year)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"PANEL BALANCE CHECK:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "expected_years = 10  # 2006-2015\n",
    "county_year_counts = df.groupby(\"county_state\")[year_col].count()\n",
    "balanced_counties = (county_year_counts == expected_years).sum()\n",
    "unbalanced_counties = (county_year_counts != expected_years).sum()\n",
    "\n",
    "print(f\"Counties with complete 10-year data: {balanced_counties}\")\n",
    "print(f\"Counties with incomplete data: {unbalanced_counties}\")\n",
    "\n",
    "if unbalanced_counties > 0:\n",
    "    print(f\"\\nFound {unbalanced_counties} counties with incomplete time series.\")\n",
    "    print(\"These counties crossed 200K population during 2006-2015.\")\n",
    "    print(\"\\nCounties with incomplete data (first 10):\")\n",
    "    incomplete = county_year_counts[county_year_counts != expected_years]\n",
    "    for county, count in incomplete.head(10).items():\n",
    "        print(f\"  - {county}: {count} years (missing {expected_years - count})\")\n",
    "    print(f\"\\nRecommendation for difference-in-differences analysis:\")\n",
    "    print(f\"  - Use only {balanced_counties} balanced counties for clean estimates\")\n",
    "    print(\"  - OR include all counties with appropriate controls\")\n",
    "else:\n",
    "    print(\"\\nAll counties have complete 10-year time series\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edf2c12",
   "metadata": {},
   "source": [
    "## Geographic Distribution\n",
    "\n",
    "Analyze state and county coverage, treatment versus control group composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "505394d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "GEOGRAPHIC COVERAGE\n",
      "============================================================\n",
      "\n",
      "States: ['California', 'Colorado', 'Florida', 'Georgia', 'Idaho', 'Mississippi', 'Montana', 'North Carolina', 'Oregon', 'South Carolina', 'Tennessee', 'Washington']\n",
      "Total states: 12\n",
      "\n",
      "Counties per state:\n",
      "STNAME\n",
      "California        33\n",
      "Florida           31\n",
      "North Carolina    18\n",
      "Georgia           14\n",
      "South Carolina    12\n",
      "Colorado          10\n",
      "Washington        10\n",
      "Tennessee          9\n",
      "Oregon             7\n",
      "Mississippi        3\n",
      "Idaho              2\n",
      "Montana            1\n",
      "Name: county_state, dtype: int64\n",
      "\n",
      "Observations per state:\n",
      "STNAME\n",
      "California        324\n",
      "Colorado          100\n",
      "Florida           299\n",
      "Georgia           130\n",
      "Idaho              20\n",
      "Mississippi        29\n",
      "Montana             4\n",
      "North Carolina    174\n",
      "Oregon             69\n",
      "South Carolina    110\n",
      "Tennessee          89\n",
      "Washington        100\n",
      "Name: count, dtype: int64\n",
      "\n",
      "------------------------------------------------------------\n",
      "TREATMENT/CONTROL CLASSIFICATION:\n",
      "------------------------------------------------------------\n",
      "TREATMENT STATES:\n",
      "  - Florida: Policy implemented 2010 (prescription limits)\n",
      "  - Washington: Policy implemented 2012 (prescription limits)\n",
      "\n",
      "CONTROL STATES:\n",
      "  - California (33 counties)\n",
      "  - Colorado (10 counties)\n",
      "  - Georgia (14 counties)\n",
      "  - Idaho (2 counties)\n",
      "  - Mississippi (3 counties)\n",
      "  - Montana (1 counties)\n",
      "  - North Carolina (18 counties)\n",
      "  - Oregon (7 counties)\n",
      "  - South Carolina (12 counties)\n",
      "  - Tennessee (9 counties)\n",
      "\n",
      "Observation distribution:\n",
      "  Florida (treatment): 299 (20.6%)\n",
      "  Washington (treatment): 100 (6.9%)\n",
      "  Control states: 1,049 (72.4%)\n"
     ]
    }
   ],
   "source": [
    "# Analyze geographic coverage and treatment/control group composition\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"GEOGRAPHIC COVERAGE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if \"county_state\" not in df.columns:\n",
    "    df[\"county_state\"] = df[\"CTYNAME\"] + \", \" + df[\"STNAME\"]\n",
    "print(f\"\\nStates: {sorted(df['STNAME'].unique())}\")\n",
    "print(f\"Total states: {df['STNAME'].nunique()}\")\n",
    "\n",
    "counties_per_state = (\n",
    "    df.groupby(\"STNAME\")[\"county_state\"].nunique().sort_values(ascending=False)\n",
    ")\n",
    "print(\"\\nCounties per state:\")\n",
    "print(counties_per_state)\n",
    "\n",
    "obs_per_state = df[\"STNAME\"].value_counts().sort_index()\n",
    "print(\"\\nObservations per state:\")\n",
    "print(obs_per_state)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"TREATMENT/CONTROL CLASSIFICATION:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"TREATMENT STATES:\")\n",
    "print(\"  - Florida: Policy implemented 2010 (prescription limits)\")\n",
    "print(\"  - Washington: Policy implemented 2012 (prescription limits)\")\n",
    "print(\"\\nCONTROL STATES:\")\n",
    "control_states = [\n",
    "    s for s in df[\"STNAME\"].unique() if s not in [\"Florida\", \"Washington\"]\n",
    "]\n",
    "for state in sorted(control_states):\n",
    "    count = df[df[\"STNAME\"] == state][\"county_state\"].nunique()\n",
    "    print(f\"  - {state} ({count} counties)\")\n",
    "\n",
    "fl_obs = df[df[\"STNAME\"] == \"Florida\"].shape[0]\n",
    "wa_obs = df[df[\"STNAME\"] == \"Washington\"].shape[0]\n",
    "control_obs = df[~df[\"STNAME\"].isin([\"Florida\", \"Washington\"])].shape[0]\n",
    "\n",
    "print(f\"\\nObservation distribution:\")\n",
    "print(f\"  Florida (treatment): {fl_obs:,} ({fl_obs/len(df)*100:.1f}%)\")\n",
    "print(f\"  Washington (treatment): {wa_obs:,} ({wa_obs/len(df)*100:.1f}%)\")\n",
    "print(f\"  Control states: {control_obs:,} ({control_obs/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f882f321",
   "metadata": {},
   "source": [
    "## Summary Statistics for Key Variables\n",
    "\n",
    "Descriptive statistics for population, mortality, and opioid shipment measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97ae1992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "KEY VARIABLE SUMMARY STATISTICS\n",
      "============================================================\n",
      "\n",
      "1. POPULATION:\n",
      "count    1.448000e+03\n",
      "mean     5.775940e+05\n",
      "std      9.403471e+05\n",
      "min      1.500850e+05\n",
      "25%      1.968205e+05\n",
      "50%      3.076625e+05\n",
      "75%      6.113122e+05\n",
      "max      1.008542e+07\n",
      "Name: population, dtype: float64\n",
      "   Min: 150,085\n",
      "   Max: 10,085,416\n",
      "   ✓ All counties ≥150K threshold: True\n",
      "\n",
      "2. DEATHS (Mortality):\n",
      "   Non-missing observations: 959 (66.2%)\n",
      "count    959.000000\n",
      "mean      54.429614\n",
      "std       56.316832\n",
      "min       10.000000\n",
      "25%       21.000000\n",
      "50%       33.000000\n",
      "75%       65.500000\n",
      "max      476.000000\n",
      "Name: Deaths, dtype: float64\n",
      "   Min: 10\n",
      "   Max: 476\n",
      "\n",
      "3. ARCOS VARIABLES:\n",
      "\n",
      "   BUYER_STATE:\n",
      "   Non-missing: 567 (39.2%)\n",
      "\n",
      "   BUYER_COUNTY:\n",
      "   Non-missing: 567 (39.2%)\n",
      "\n",
      "   TOTAL_MME:\n",
      "   Non-missing: 567 (39.2%)\n",
      "   Mean: 7,705,074,974.72\n",
      "   Median: 256,802,921.99\n",
      "   Range: [54,897,545.44, 4,174,281,314,231.23]\n",
      "\n",
      "4. MORTALITY RATE (per 100,000 population):\n",
      "   Mean: 12.62\n",
      "   Median: 11.43\n",
      "   Range: [2.59, 68.31]\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics for population, mortality, and opioid shipment measures\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"KEY VARIABLE SUMMARY STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Population\n",
    "print(\"\\n1. POPULATION:\")\n",
    "print(df[\"population\"].describe())\n",
    "print(f\"   Min: {df['population'].min():,.0f}\")\n",
    "print(f\"   Max: {df['population'].max():,.0f}\")\n",
    "print(f\"   ✓ All counties ≥150K threshold: {(df['population'] >= 150000).all()}\")\n",
    "\n",
    "# Deaths\n",
    "print(\"\\n2. DEATHS (Mortality):\")\n",
    "deaths_nonmissing = df[\"Deaths\"].dropna()\n",
    "print(\n",
    "    f\"   Non-missing observations: {len(deaths_nonmissing):,} ({len(deaths_nonmissing)/len(df)*100:.1f}%)\"\n",
    ")\n",
    "print(deaths_nonmissing.describe())\n",
    "print(f\"   Min: {deaths_nonmissing.min():.0f}\")\n",
    "print(f\"   Max: {deaths_nonmissing.max():.0f}\")\n",
    "\n",
    "# Check for ARCOS variables (MME, DOSAGE_UNIT, etc.)\n",
    "arcos_cols = [\n",
    "    col\n",
    "    for col in df.columns\n",
    "    if any(x in col.upper() for x in [\"MME\", \"DOSAGE\", \"BUYER\"])\n",
    "]\n",
    "if arcos_cols:\n",
    "    print(\"\\n3. ARCOS VARIABLES:\")\n",
    "    for col in arcos_cols[:3]:\n",
    "        nonmissing = df[col].dropna()\n",
    "        print(f\"\\n   {col}:\")\n",
    "        print(\n",
    "            f\"   Non-missing: {len(nonmissing):,} ({len(nonmissing)/len(df)*100:.1f}%)\"\n",
    "        )\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            print(f\"   Mean: {nonmissing.mean():,.2f}\")\n",
    "            print(f\"   Median: {nonmissing.median():,.2f}\")\n",
    "            print(f\"   Range: [{nonmissing.min():,.2f}, {nonmissing.max():,.2f}]\")\n",
    "\n",
    "# Calculate mortality rate per 100K\n",
    "if \"Deaths\" in df.columns:\n",
    "    df[\"mortality_rate_per_100k\"] = (df[\"Deaths\"] / df[\"population\"]) * 100000\n",
    "    print(\"\\n4. MORTALITY RATE (per 100,000 population):\")\n",
    "    mort_rate = df[\"mortality_rate_per_100k\"].dropna()\n",
    "    print(f\"   Mean: {mort_rate.mean():.2f}\")\n",
    "    print(f\"   Median: {mort_rate.median():.2f}\")\n",
    "    print(f\"   Range: [{mort_rate.min():.2f}, {mort_rate.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bc2418",
   "metadata": {},
   "source": [
    "## Data Integrity Validation\n",
    "\n",
    "Check for data quality issues: duplicate observations, negative values, logical inconsistencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51e2166b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATA INTEGRITY CHECKS\n",
      "============================================================\n",
      "\n",
      "1. NEGATIVE VALUE CHECK:\n",
      "   ✓ No negative values found in numeric columns\n",
      "\n",
      "2. POPULATION THRESHOLD:\n",
      "   ⚠ WARNING: 381 observations below 200K threshold!\n",
      "\n",
      "3. YEAR RANGE:\n",
      "   ✓ All expected years present (2006-2015)\n",
      "\n",
      "4. DUPLICATE CHECK:\n",
      "   ✓ No duplicate county-year observations\n",
      "\n",
      "5. LOGICAL CONSISTENCY:\n",
      "   ✓ No observations with deaths exceeding population\n"
     ]
    }
   ],
   "source": [
    "# Data integrity checks: negative values, threshold, year range, duplicates, logical consistency\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATA INTEGRITY CHECKS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if \"county_state\" not in df.columns:\n",
    "    df[\"county_state\"] = df[\"CTYNAME\"] + \", \" + df[\"STNAME\"]\n",
    "# Check 1: No negative values\n",
    "print(\"\\n1. NEGATIVE VALUE CHECK:\")\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "has_negatives = False\n",
    "for col in numeric_cols:\n",
    "    if (df[col] < 0).any():\n",
    "        neg_count = (df[col] < 0).sum()\n",
    "        print(f\"   ⚠ {col}: {neg_count} negative values\")\n",
    "        has_negatives = True\n",
    "if not has_negatives:\n",
    "    print(\"   ✓ No negative values found in numeric columns\")\n",
    "# Check 2: Population threshold validation\n",
    "print(\"\\n2. POPULATION THRESHOLD:\")\n",
    "below_threshold = (df[\"population\"] < 200000).sum()\n",
    "if below_threshold > 0:\n",
    "    print(f\"   ⚠ WARNING: {below_threshold} observations below 200K threshold!\")\n",
    "else:\n",
    "    print(\"   ✓ All observations meet ≥200K population threshold\")\n",
    "# Check 3: Year range validation\n",
    "print(\"\\n3. YEAR RANGE:\")\n",
    "expected_years = set(range(2006, 2016))\n",
    "actual_years = set(df[year_col].unique())\n",
    "if actual_years == expected_years:\n",
    "    print(\"   ✓ All expected years present (2006-2015)\")\n",
    "else:\n",
    "    missing_years = expected_years - actual_years\n",
    "    extra_years = actual_years - expected_years\n",
    "    if missing_years:\n",
    "        print(f\"   ⚠ Missing years: {missing_years}\")\n",
    "    if extra_years:\n",
    "        print(f\"   ⚠ Unexpected years: {extra_years}\")\n",
    "# Check 4: Duplicate observations (using county_state identifier)\n",
    "print(\"\\n4. DUPLICATE CHECK:\")\n",
    "id_cols = [\"county_state\", year_col]\n",
    "duplicates = df.duplicated(subset=id_cols).sum()\n",
    "if duplicates > 0:\n",
    "    print(f\"   ⚠ WARNING: {duplicates} duplicate county-year observations!\")\n",
    "    print(\"\\n   Sample duplicate rows:\")\n",
    "    dup_mask = df.duplicated(subset=id_cols, keep=False)\n",
    "    print(df[dup_mask][[\"county_state\", year_col, \"population\", \"Deaths\"]].head(10))\n",
    "else:\n",
    "    print(\"   ✓ No duplicate county-year observations\")\n",
    "# Check 5: Deaths > Population (impossible)\n",
    "print(\"\\n5. LOGICAL CONSISTENCY:\")\n",
    "if \"Deaths\" in df.columns:\n",
    "    impossible = (df[\"Deaths\"] > df[\"population\"]).sum()\n",
    "    if impossible > 0:\n",
    "        print(f\"   ⚠ WARNING: {impossible} observations with deaths > population!\")\n",
    "    else:\n",
    "        print(\"   ✓ No observations with deaths exceeding population\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac76ac5",
   "metadata": {},
   "source": [
    "## Extreme Outlier Detection\n",
    "\n",
    "Identify and remove data errors in opioid shipment totals (values >10 billion MME indicate upstream supply chain transactions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "516d5529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXTREME OUTLIER DETECTION\n",
      "============================================================\n",
      "\n",
      "Checking TOTAL_MME for extreme outliers...\n",
      "\n",
      "⚠ Found 1 extreme outliers (>10 billion MME):\n",
      "   Lane County, Oregon, 2010: 4,174,281,314,231 MME\n",
      "\n",
      "Removing 1 extreme outliers...\n",
      "✓ Cleaned dataset saved (566 observations remaining)\n"
     ]
    }
   ],
   "source": [
    "# Detect and remove extreme outliers in opioid shipment totals\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXTREME OUTLIER DETECTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if \"county_state\" not in df.columns:\n",
    "    df[\"county_state\"] = df[\"CTYNAME\"] + \", \" + df[\"STNAME\"]\n",
    "if \"TOTAL_MME\" in df.columns:\n",
    "    print(\"\\nChecking TOTAL_MME for extreme outliers...\")\n",
    "    extreme_threshold = 1e10\n",
    "    extreme_outliers = df[df[\"TOTAL_MME\"] > extreme_threshold]\n",
    "    if len(extreme_outliers) > 0:\n",
    "        print(f\"\\n⚠ Found {len(extreme_outliers)} extreme outliers (>10 billion MME):\")\n",
    "        for idx, row in extreme_outliers.iterrows():\n",
    "            print(\n",
    "                f\"   {row['county_state']}, {row[year_col]}: {row['TOTAL_MME']:,.0f} MME\"\n",
    "            )\n",
    "        print(f\"\\nRemoving {len(extreme_outliers)} extreme outliers...\")\n",
    "        df = df[df[\"TOTAL_MME\"] <= extreme_threshold].copy()\n",
    "        df.to_csv(\"../01_data/clean/final_merged_150k.csv\", index=False)\n",
    "        print(f\"✓ Cleaned dataset saved ({len(df)} observations remaining)\")\n",
    "    else:\n",
    "        print(\"✓ No extreme outliers detected\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
